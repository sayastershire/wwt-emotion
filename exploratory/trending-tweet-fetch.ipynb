{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('../credential/bearer_token.txt') as f:\n",
    "    BEARER_TOKEN = f.read()\n",
    "\n",
    "t_h = twitter.Twitter(auth=twitter.OAuth2(bearer_token=BEARER_TOKEN))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                        name  \\\n0           0                        xiao   \n1           1                    #AMAsTNT   \n2           2                   #BTSxAMAs   \n3           3  #TelkomDukungUMKMmandalika   \n4           4       #IVE_1st_ConceptPhoto   \n5           5           #IkatanCintaEp520   \n6           6                      Nessie   \n7           7                 Edi Witjara   \n8           8                  Mas Gilang   \n9           9                       Ariel   \n\n                                                 url  promoted_content  \\\n0                   http://twitter.com/search?q=xiao               NaN   \n1             http://twitter.com/search?q=%23AMAsTNT               NaN   \n2            http://twitter.com/search?q=%23BTSxAMAs               NaN   \n3  http://twitter.com/search?q=%23TelkomDukungUMK...               NaN   \n4  http://twitter.com/search?q=%23IVE_1st_Concept...               NaN   \n5    http://twitter.com/search?q=%23IkatanCintaEp520               NaN   \n6                 http://twitter.com/search?q=Nessie               NaN   \n7      http://twitter.com/search?q=%22Edi+Witjara%22               NaN   \n8       http://twitter.com/search?q=%22Mas+Gilang%22               NaN   \n9                  http://twitter.com/search?q=Ariel               NaN   \n\n                          query  tweet_volume  \n0                          xiao       51789.0  \n1                    %23AMAsTNT     8607535.0  \n2                   %23BTSxAMAs     5166619.0  \n3  %23TelkomDukungUMKMmandalika           NaN  \n4       %23IVE_1st_ConceptPhoto       11268.0  \n5           %23IkatanCintaEp520           NaN  \n6                        Nessie       20606.0  \n7             %22Edi+Witjara%22           NaN  \n8              %22Mas+Gilang%22           NaN  \n9                         Ariel       19763.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>name</th>\n      <th>url</th>\n      <th>promoted_content</th>\n      <th>query</th>\n      <th>tweet_volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>xiao</td>\n      <td>http://twitter.com/search?q=xiao</td>\n      <td>NaN</td>\n      <td>xiao</td>\n      <td>51789.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>#AMAsTNT</td>\n      <td>http://twitter.com/search?q=%23AMAsTNT</td>\n      <td>NaN</td>\n      <td>%23AMAsTNT</td>\n      <td>8607535.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>#BTSxAMAs</td>\n      <td>http://twitter.com/search?q=%23BTSxAMAs</td>\n      <td>NaN</td>\n      <td>%23BTSxAMAs</td>\n      <td>5166619.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>#TelkomDukungUMKMmandalika</td>\n      <td>http://twitter.com/search?q=%23TelkomDukungUMK...</td>\n      <td>NaN</td>\n      <td>%23TelkomDukungUMKMmandalika</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>#IVE_1st_ConceptPhoto</td>\n      <td>http://twitter.com/search?q=%23IVE_1st_Concept...</td>\n      <td>NaN</td>\n      <td>%23IVE_1st_ConceptPhoto</td>\n      <td>11268.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>#IkatanCintaEp520</td>\n      <td>http://twitter.com/search?q=%23IkatanCintaEp520</td>\n      <td>NaN</td>\n      <td>%23IkatanCintaEp520</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Nessie</td>\n      <td>http://twitter.com/search?q=Nessie</td>\n      <td>NaN</td>\n      <td>Nessie</td>\n      <td>20606.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Edi Witjara</td>\n      <td>http://twitter.com/search?q=%22Edi+Witjara%22</td>\n      <td>NaN</td>\n      <td>%22Edi+Witjara%22</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Mas Gilang</td>\n      <td>http://twitter.com/search?q=%22Mas+Gilang%22</td>\n      <td>NaN</td>\n      <td>%22Mas+Gilang%22</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Ariel</td>\n      <td>http://twitter.com/search?q=Ariel</td>\n      <td>NaN</td>\n      <td>Ariel</td>\n      <td>19763.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jak_trend = pd.read_csv('../dataset/trend.txt')\n",
    "jak_trend.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['xiao', '#AMAsTNT', '#BTSxAMAs', '#TelkomDukungUMKMmandalika',\n       '#IVE_1st_ConceptPhoto', '#IkatanCintaEp520', 'Nessie',\n       'Edi Witjara', 'Mas Gilang', 'Ariel', 'MEW MEW SO HOT', 'Ngeluh',\n       'ITDC Group', 'Shenhe', 'MS Glow', 'SPBU', 'Arsyad', 'Kojic',\n       'YESEO FOR DAZED', 'Wine', 'Healing', 'Juragan', 'Marriage',\n       'Arteria', 'Bram', 'Sapu', 'Yunjin', 'Penjilat', 'Polearm',\n       'Provinsi Jawa', 'Selingkuh', 'Sejarah', 'Karma', 'Emil Salim',\n       'Operasi', 'SF9 TRAUMA OUT NOW', 'Jaksel', 'Dp 150k', 'Ganyu',\n       'Eula', 'EMS TAX', 'ayato', 'OPEN PO', 'Itto', 'Eunkwang',\n       'TBL TBL TBL', 'GO Line', '#peShan', '#Seungmin', '#HARUKYU'],\n      dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jak_trend.get('name').values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting xiao... Done!\n",
      "Starting #AMAsTNT... Done!\n",
      "Starting #BTSxAMAs... Done!\n",
      "Starting #TelkomDukungUMKMmandalika... "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'retweeted_status'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'retweeted_status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16948/1050880078.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[1;31m# Get full text, put it in a new header\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0mquery_rt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mquery\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'retweeted_status'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m                 \u001B[0mquery_rt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'full_text'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'retweeted_status'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "for trend in jak_trend.get('name').values:\n",
    "    print('Starting', trend, end='... ')\n",
    "    tweet_df = pd.DataFrame()\n",
    "    max_tweets = 300\n",
    "    since_id_buff = ''\n",
    "\n",
    "    # Loop. Expect the amount of tweets fetched to exceed the value of max_tweets a bit. Each of the following tweets will be unique.\n",
    "    while len(tweet_df) < max_tweets:\n",
    "        query = t_h.search.tweets(q=trend, lang='en', count=100, tweet_mode='extended') if since_id_buff == '' else t_h.search.tweets(q=trend, lang='en', count=100, tweet_mode='extended', max_id=since_id_buff)\n",
    "        since_id_buff = re.search(r'max_id=(.+)&q', query['search_metadata']['next_results']).group(1)\n",
    "        query = pd.DataFrame(query['statuses'])\n",
    "\n",
    "        # Get full text, put it in a new header\n",
    "        query_rt = []\n",
    "        for i in query['retweeted_status']:\n",
    "            try:\n",
    "                query_rt.append(i['full_text'])\n",
    "            except:\n",
    "                query_rt.append(np.nan)\n",
    "        # print(query_rt)\n",
    "        query_text = []\n",
    "        for i in range(len(query_rt)):\n",
    "            # print(i, end='\\r')\n",
    "            query_text.append(query_rt[i] if not pd.isnull(query_rt[i]) else query['full_text'].loc[i])\n",
    "\n",
    "        query['inferred_text'] = query_text\n",
    "\n",
    "        # Fixing\n",
    "        tweet_df = tweet_df.append(query).reset_index().drop('index', axis=1) if tweet_df is not None else query\n",
    "\n",
    "        if len(tweet_df) >= max_tweets:\n",
    "            tweet_df = tweet_df.drop_duplicates(subset=['inferred_text']).reset_index().drop('index', axis=1)\n",
    "\n",
    "    tweet_df.to_json('../dataset/trends/'+trend+'.json', orient='index')\n",
    "    print('Done!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(314, 32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the last tweet dataframe\n",
    "tweet_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['created_at', 'id', 'id_str', 'full_text', 'truncated',\n       'display_text_range', 'entities', 'metadata', 'source',\n       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n       'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count',\n       'favorite_count', 'favorited', 'retweeted', 'lang', 'extended_entities',\n       'possibly_sensitive', 'quoted_status_id', 'quoted_status_id_str',\n       'quoted_status', 'inferred_text'],\n      dtype='object')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "tweet_df.to_json('../dataset/trends/nyoba.json', orient='index')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}